{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "Name: Annabelle Nguyen\n",
    "\n",
    "Email: huonganh.nguyen@duke.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print_function for compatibility with Python 3\n",
    "from __future__ import print_function\n",
    "\n",
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# StandardScaler from Scikit-Learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PCA from Scikit-Learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scikit-Learn's KMeans algorithm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data set\n",
    "df = pd.read_csv(\"~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/customer_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the dimensions of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the data types of each column in the dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the top 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# descriptive statistics for numeric variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# descriptive statistics for categorical variables\n",
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# column \"Unnamed: 0\" is meaningless, so it will be dropped\n",
    "# column \"source\" contains only 1 value, so it will be dropped\n",
    "df1 = df.drop([\"Unnamed: 0\", \"source\"], axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level of information: product ID per order per customer (or transaction level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for any missing data by variable\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is clean. Missing values in days_since_prior_order is acceptable because first-time customers don't have prior records of purchases.\n",
    "\n",
    "df1 is the analytical base table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of unique product_id\n",
    "len(df1.product_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at some patterns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of times each product has been bought\n",
    "product_count = df1.groupby([\"product_id\", \"product_name\"]).size().sort_values(ascending = False).reset_index()\n",
    "product_count.columns = [\"product_id\", \"product_name\", \"number_of_items_sold\"]\n",
    "product_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store the top 10 most popular products in a new dataframe\n",
    "top10products = df1.groupby([\"product_id\", \"product_name\"]).size().sort_values(ascending = False).reset_index().head(10)\n",
    "top10products.columns = ['product_id', 'product_name', 'number_of_items_sold']\n",
    "top10products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of products/items each customer has bought at the grocery store\n",
    "products_per_cust = df1.groupby([\"cust_id\"]).agg({'product_id': [np.size]}).sort_values([('product_id','size')], ascending=False).reset_index()\n",
    "products_per_cust.columns = products_per_cust.columns.map(''.join)\n",
    "products_per_cust.columns = ['cust_id', 'number_of_items']\n",
    "products_per_cust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of times each customer has shopped at the grocery store\n",
    "shopping_frequency = df1.groupby([\"cust_id\"]).agg({'order_id': [np.size]}).sort_values([('order_id','size')], ascending=False).reset_index()\n",
    "shopping_frequency.columns = shopping_frequency.columns.map(''.join)\n",
    "shopping_frequency.columns = ['cust_id', 'total_visits']\n",
    "shopping_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count the number of products per order\n",
    "order_size = df1.groupby([\"order_id\"]).agg({'product_id': [np.size]}).sort_values([('product_id','size')], ascending=False).reset_index()\n",
    "order_size.columns = order_size.columns.map(''.join)\n",
    "order_size.columns = ['order_id', 'order_size']\n",
    "order_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aggregate total visits and total products bought by each cust_id\n",
    "cust_df = df1.groupby([\"cust_id\"]).agg({'order_id': [np.size], 'product_id': [np.size]}).reset_index()\n",
    "cust_df.columns = cust_df.columns.map(''.join)\n",
    "cust_df.columns = ['cust_id', 'total_visits', 'total_products']\n",
    "cust_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the steps for dimensionality reduction on a small sample of 2 customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pull out 2 random customers to create a test dataframe\n",
    "test_df = df1[df1.cust_id.isin([30, 201027])]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the product IDs into dummy variables (test_df)\n",
    "test_item_dummies = pd.get_dummies(test_df.product_id)\n",
    "\n",
    "# Add cust_id to toy_item_dummies\n",
    "test_item_dummies['cust_id'] = test_df.cust_id\n",
    "\n",
    "# Display test_item_dummies\n",
    "test_item_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregate test_items_dummies at the customer level\n",
    "test_item_data = test_item_dummies.groupby('cust_id').sum()\n",
    "test_item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to set the threshold, apply the steps for dimensionality reduction on the full data set, only pulling out the top 10 most popular products. Because the data set is too large (around 32 million rows), converting product_id into categorical variables is too computationally demanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get a list of product_id from top10products data set\n",
    "top10productid = list(top10products.product_id)\n",
    "top10productid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the clean data set (df1) for only the top 10 most popular products\n",
    "df1_top_10_items = df1[df1.product_id.isin(top10productid)]\n",
    "df1_top_10_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the dimensions of df1_top_10_items\n",
    "df1_top_10_items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert product_id in df1_top_10_items into dummy variables\n",
    "top_10_item_data = pd.get_dummies(df1_top_10_items.product_id)\n",
    "\n",
    "# Add cust_id to top_10_item_data\n",
    "top_10_item_data['cust_id'] = df1_top_10_items.cust_id\n",
    "\n",
    "# Display top_10_item_data\n",
    "top_10_item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the top_10_item_data\n",
    "top_10_item_data.to_csv(\"~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/top_10_item_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert product_id into categorical variable for the entire clean data set, only pulling out the top 10 frequent shoppers. Converting product_id into categorical variables for the entire data set is too computationally demanding and kills the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a list of the top 10 cust_id from shopping_frequency data set\n",
    "top10custid = list(shopping_frequency.head(10).cust_id)\n",
    "top10custid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the clean data set (df1) for only the top 10 most frequent shoppers\n",
    "df1_top_10_shoppers = df1[df1.cust_id.isin(top10custid)]\n",
    "df1_top_10_shoppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert product_id in unique_products into dummy variables\n",
    "top_10_shopper_data = pd.get_dummies(df1_top_10_shoppers.product_id)\n",
    "\n",
    "# Add cust_id to top_10_shopper_data\n",
    "top_10_shopper_data['cust_id'] = df1_top_10_shoppers.cust_id\n",
    "\n",
    "# Display top_10_shopper_data\n",
    "top_10_shopper_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the dimensions of the top_10_shopper_data\n",
    "top_10_shopper_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save top_10_shopper_data\n",
    "top_10_shopper_data.to_csv(\"~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/top_10_shopper_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display the dimensions of top_10_item_data\n",
    "top_10_item_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display the dimensions of top_10_shopper_data\n",
    "top_10_shopper_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add an index column to top_10_shopper_data\n",
    "top_10_shopper_data_index = pd.read_csv('~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/top_10_shopper_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform X\n",
    "X_scaled = scaler.fit_transform(top_10_shopper_data_index)\n",
    "\n",
    "# Display first 5 rows of X_scaled\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit and transform top_10_shopper_data_index\n",
    "top_10_shopper_data_index_scaled = scaler.fit_transform(top_10_shopper_data_index)\n",
    "\n",
    "# Display first 5 rows of top_10_shopper_data_index\n",
    "top_10_shopper_data_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize and fit a PCA transformation\n",
    "pca = PCA()\n",
    "pca.fit(top_10_shopper_data_index_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate new features\n",
    "PC_items = pca.transform(top_10_shopper_data_index_scaled)\n",
    "\n",
    "# Display first 5 rows\n",
    "PC_items[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sum of explained variance ratio\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cumulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(len(cumulative_explained_variance)), cumulative_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How much variance we'd capture with the first 2600 components\n",
    "cumulative_explained_variance[2600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 2600 components can explain about 80% of the variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize PCA transformation, only keeping 100 components\n",
    "pca = PCA(n_components=2600)\n",
    "\n",
    "# Fit and transform top_10_shopper_data_index_scaled\n",
    "PC_items = pca.fit_transform(top_10_shopper_data_index_scaled)\n",
    "\n",
    "# Display shape of PC_items\n",
    "PC_items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the top_10_shopper_data has been reduced from 3281 variables to 2600 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put PC_items into a dataframe\n",
    "items_pca = pd.DataFrame(PC_items)\n",
    "\n",
    "# Name the columns\n",
    "items_pca.columns = ['PC{}'.format(i + 1) for i in range(PC_items.shape[1])]\n",
    "\n",
    "# Update its index\n",
    "items_pca.index = top_10_shopper_data.index\n",
    "\n",
    "# Display first 5 rows\n",
    "items_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save pca_item_data.csv\n",
    "items_pca.to_csv('~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/pca_item_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save analytical base table\n",
    "df1.to_csv(\"~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/ABT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import analytical base table\n",
    "base_df = pd.read_csv('~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/ABT.csv', index_col=0)\n",
    "\n",
    "# Import thresholded item features\n",
    "threshold_item_data = pd.read_csv('~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/top_10_item_data.csv', index_col=0)\n",
    "\n",
    "# Import PCA item features\n",
    "pca_item_data = pd.read_csv('~/Box Sync/Duke MQM/5. Spring 2/Advanced Analytics & Applications/Assignment 3/pca_item_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print shape of each dataframe\n",
    "print( base_df.shape )\n",
    "print( threshold_item_data.shape )\n",
    "print( pca_item_data.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join base_df with threshold_item_data\n",
    "threshold_df = base_df.merge(threshold_item_data, left_on='cust_id', right_on='cust_id', how='right')\n",
    "\n",
    "# Display first 5 rows of threshold_df\n",
    "threshold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join base_df with pca_item_data\n",
    "pca_df = base_df.merge(pca_item_data, left_on='cust_id', right_on='cust_id', how='right')\n",
    "\n",
    "# Display first 5 rows of pca_df\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct k-means on base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-Means model pipeline\n",
    "k_means = make_pipeline(StandardScaler(), KMeans(n_clusters=3, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit K-Means pipeline\n",
    "k_means.fit(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save clusters to base_df\n",
    "base_df['cluster'] = k_means.predict(base_df)\n",
    "\n",
    "# Display first 5 rows of base_df\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot, colored by cluster\n",
    "sns.lmplot(x='total_sales', y='avg_cart_value', hue='cluster', data=base_df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, conduct k-means on threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-Means model pipeline\n",
    "k_means = make_pipeline(StandardScaler(), KMeans(n_clusters=3, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit K-Means pipeline\n",
    "k_means.fit(threshold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save clusters to threshold_df\n",
    "threshold_df['cluster'] = k_means.predict(threshold_df)\n",
    "\n",
    "# Display first 5 rows of threshold_df\n",
    "threshold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot, colored by cluster\n",
    "sns.lmplot(x='total_sales', y='avg_cart_value', hue='cluster', data=threshold_df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, conduct k-means on pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-Means model pipeline\n",
    "k_means = make_pipeline(StandardScaler(), KMeans(n_clusters=3, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit K-Means pipeline\n",
    "k_means.fit(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save clusters to pca_df\n",
    "pca_df['cluster'] = k_means.predict(pca_df)\n",
    "\n",
    "# Display first 5 rows of pca_df\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot, colored by cluster\n",
    "sns.lmplot(x='total_sales', y='avg_cart_value', hue='cluster', data=pca_df, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check all indices are identical\n",
    "print( all( base_df.index == threshold_df.index ) )\n",
    "print( all( base_df.index == pca_df.index) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjusted Rand index\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similary between base_df.cluster and threshold_df.cluster\n",
    "adjusted_rand_score(base_df.cluster, threshold_df.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similary between threshold_df.cluster and base_df.cluster\n",
    "adjusted_rand_score(threshold_df.cluster, pca_df.cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similary between base_df.cluster and pca_df.cluster\n",
    "adjusted_rand_score(base_df.cluster, pca_df.cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
